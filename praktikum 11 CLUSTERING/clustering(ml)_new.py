# -*- coding: utf-8 -*-
"""Clustering(ML)_new.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1iIoqnhF3XqCfp3pF3fQ6q89wfJ85nNNI

# Initialize Library and read Data

we use some library to do clustering and analyze the clusters
"""

import pandas as pd
from sklearn.cluster import KMeans
from sklearn.cluster import AgglomerativeClustering
from sklearn.metrics import silhouette_score
from yellowbrick.cluster import SilhouetteVisualizer
from yellowbrick.cluster import KElbowVisualizer

dataset = pd.read_csv('ruspini.csv')
data = dataset.loc[:,['X','Y']]

data

"""# K-Means Clustering
Dokumentasi sklearn.cluster.KMeans:

https://scikit-learn.org/stable/modules/generated/sklearn.cluster.KMeans.html

Beberapa parameter penting yang berhubungan dengan praktikum ini:


*   n_clusters: *int*, banyak cluster atau k
*   init: *{‘k-means++’, ‘random’}*. **'k-means++' parameter** initializes the centroids to be (generally) distant from each other, leading to probably better results than random initialization, as shown in the reference. **random** choose n_clusters observations (rows) at random from data for the initial centroids
*   n_init: *‘auto’ or int*. n kali centroid dibangkitkan sebelum dijadikan centroid awal.
"""

kmeans=KMeans(n_clusters=4, init="random", n_init=1)
clusters = kmeans.fit_predict(data)

print(kmeans.get_params(deep=False))

print('\nHasil KMeans Clustering:\n', clusters)

data.plot(x='X', y='Y', kind='scatter', c=clusters, colormap='Paired') #only 2D data

"""## Cluster Analysis (Silhoutte Score)
Dalam analisa cluster yang disediakan oleh library scikit.learn untuk kmeans ada SSE. Analisa paling umum dan banyak digunakan adalah silhoutte score (https://en.wikipedia.org/wiki/Silhouette_(clustering))

The best **Silhoutte Score** value is 1 and the worst value is -1. Values near 0 indicate overlapping clusters. Negative values generally indicate that a sample has been assigned to the wrong cluster, as a different cluster is more similar. Over 0.7 is considered to be "strong", a value over 0.5 "reasonable" and over 0.25 "weak".
"""

print('\nCluster Analysis\n')
print('SSE (inertia): ', kmeans.inertia_)
print('\nSilhoutte Score: ', silhouette_score(data,clusters))
print('\n')

visualizer = SilhouetteVisualizer(kmeans, colors='yellowbrick') #hanya bisa di KMeans
visualizer.fit(data)        # Fit the data to the visualizer
visualizer.show()        # Finalize and render the figure

"""## Elbow Plot
***Automatic Clustering:*** Istilah ini muncul disaat kita menentukan banyak jumlah klaster secara otomatis. Salah satu metode untuk menentukan klaster mana yang terbaik adalah Elbow Method.

Elbow plot: menentukan jumlah **cluster optimal** dengan menggunakan nilai  within-cluster sum of squares (WCSS).WCSS mengukur sum of squared antara setiap titik data dan pusat clusternya (centroid). Elbow point menunjukan titik dimana tingkat penurunan WCSS mulai mendatar.

"""

visualizer = KElbowVisualizer(kmeans, k=(1,12))

visualizer.fit(data)        # Fit the data to the visualizer
visualizer.show()        # Finalize and render the figure

"""# Hiearchical (Agglomerative) Clustering
Dokumentasi sklearn.cluster.AgglomerativeClustering:

https://scikit-learn.org/stable/modules/generated/sklearn.cluster.AgglomerativeClustering.html

Beberapa parameter penting yang berhubungan dengan praktikum ini:


*   n_clusters: *int*, banyak cluster atau k
*   linkage: *{‘ward’, ‘complete’, ‘average’, ‘single’}*, Which linkage criterion to use. The linkage criterion determines which distance to use between sets of observation. The algorithm will merge the pairs of cluster that minimize this criterion.

  1.  ‘ward’ minimizes the variance(the sum of squared differences within all clusters) of the clusters being merged.

  2.  ‘average’ uses the average of the distances of each observation of the two sets.

  3.  ‘complete’ or ‘maximum’ linkage uses the maximum distances between all observations of the two sets.

  4.  ‘single’ uses the minimum of the distances between all observations of the two sets.
"""

hclust = AgglomerativeClustering(n_clusters = 4, linkage = 'average')
hclusters = hclust.fit_predict(data)

print(hclust.get_params(deep=False))

print('\nHasil Agglomerative Clustering:\n', hclusters)

data.plot(x='X', y='Y', kind='scatter', c=hclusters, colormap='Paired') #only 2D data

"""## Cluster Analysis (Silhoutte Score)"""

print('\nCluster Analysis')
print('\nSilhoutte Score: ', silhouette_score(data,hclusters))

"""## Elbow Plot"""

visualizer = KElbowVisualizer(hclust, k=(1,12))

visualizer.fit(data)        # Fit the data to the visualizer
visualizer.show()        # Finalize and render the figure

"""# Tugas (Assignment)

  1. dataset << milk.csv, dan tampilkan
  2. ambil data pada semua atribut, kecuali class
  3. data << normalisasi dengan min-max (0-1)
  4. cluster << lakukan clustering pada data menggunkan K-Means (k=3), sebanyak 10 kali. Setiap kali selesai clustering, lakukan cluster analysis dengan SSE dan Silhoutte Score. Berapa nilai SSE dan Silhoutte Score terbaik dan tampilkan Silhoutte Plotnya!
  5. Berapa nilai k terbaik dari cluster K-Means dengan menggunakan Elbow Plot?
  6. cluster << lakukan clustering pada data dengan menggunakan Single, Average, Complete Linkage dengan k=3. Tampilkan hasil cluster setiap linkage dan algoritma mana yang memiliki nilai Silhoutte score terbaik?
  7. Berapa nilai k terbaik (menggunakan Elbow Plot) dari cluster Hierarchical clustering di Single, Average, dan Complete Linkage?
  8. Berilah kesimpulan mana nilai K dan Algoritma Clustering yang terbaik untuk data milk.csv dan jelaskan alasannya!
"""